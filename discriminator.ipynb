{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('Train.csv', sep=',')\n",
    "test_data = pd.read_csv('Test.csv', sep=',')\n",
    "valid_data = pd.read_csv('Valid.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(data):\n",
    "    html_pat = re.compile('<.*?>')\n",
    "    punctuation_pat = re.compile('[\"?!#$%&\\'()*+,-./:;<=>@[\\\\]^_`{|}~ ]')\n",
    "    \n",
    "    sentences = []\n",
    "    \n",
    "    for i, text in enumerate(data['text']):\n",
    "        filtered_text = html_pat.sub('', text)\n",
    "        words = list(filter(lambda x:x!='', punctuation_pat.split(filtered_text)))\n",
    "        sentences.append(words)\n",
    "        \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = split(train_data)\n",
    "test = split(test_data)\n",
    "valid = split(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'grew', 'up', 'b', '1965', 'watching', 'and', 'loving', 'the', 'Thunderbirds', 'All', 'my', 'mates', 'at', 'school', 'watched', 'We', 'played', 'Thunderbirds', 'before', 'school', 'during', 'lunch', 'and', 'after', 'school', 'We', 'all', 'wanted', 'to', 'be', 'Virgil', 'or', 'Scott', 'No', 'one', 'wanted', 'to', 'be', 'Alan', 'Counting', 'down', 'from', '5', 'became', 'an', 'art', 'form', 'I', 'took', 'my', 'children', 'to', 'see', 'the', 'movie', 'hoping', 'they', 'would', 'get', 'a', 'glimpse', 'of', 'what', 'I', 'loved', 'as', 'a', 'child', 'How', 'bitterly', 'disappointing', 'The', 'only', 'high', 'point', 'was', 'the', 'snappy', 'theme', 'tune', 'Not', 'that', 'it', 'could', 'compare', 'with', 'the', 'original', 'score', 'of', 'the', 'Thunderbirds', 'Thankfully', 'early', 'Saturday', 'mornings', 'one', 'television', 'channel', 'still', 'plays', 'reruns', 'of', 'the', 'series', 'Gerry', 'Anderson', 'and', 'his', 'wife', 'created', 'Jonatha', 'Frakes', 'should', 'hand', 'in', 'his', 'directors', 'chair', 'his', 'version', 'was', 'completely', 'hopeless', 'A', 'waste', 'of', 'film', 'Utter', 'rubbish', 'A', 'CGI', 'remake', 'may', 'be', 'acceptable', 'but', 'replacing', 'marionettes', 'with', 'Homo', 'sapiens', 'subsp', 'sapiens', 'was', 'a', 'huge', 'error', 'of', 'judgment']\n"
     ]
    }
   ],
   "source": [
    "print(train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_length(sentence):\n",
    "    return list(map(lambda x:len(x), sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1000.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18,5), sharex=True, sharey=True)\n",
    "data=pd.DataFrame(sentence_length(train), columns=['train'], )\n",
    "sns.histplot(data=data, x='train', ax=axes[0])\n",
    "\n",
    "data=pd.DataFrame(sentence_length(test), columns=['test'])\n",
    "sns.histplot(data=data, x='test', ax=axes[1])\n",
    "\n",
    "data=pd.DataFrame(sentence_length(valid), columns=['valid'])\n",
    "sns.histplot(data=data, x='valid', ax=axes[2])\n",
    "\n",
    "plt.subplots_adjust(wspace=0.05)\n",
    "plt.xlim(0,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align(sentence, length):\n",
    "    if len(sentence) < length:\n",
    "        return sentence + ['<PAD>' for x in range(length - len(sentence))]\n",
    "    else:\n",
    "        return sentence[:length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = list(map(lambda x: align(x, 250), train))\n",
    "test = list(map(lambda x: align(x, 250), test))\n",
    "valid = list(map(lambda x: align(x, 250), valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "def stemming(sentence, stemmer):\n",
    "    return [stemmer.stem(word) for word in sentence]\n",
    "\n",
    "train = list(map(lambda x:stemming(x, stemmer), train))\n",
    "test = list(map(lambda x:stemming(x, stemmer), test))\n",
    "valid = list(map(lambda x:stemming(x, stemmer), valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(data):\n",
    "    word_count = {}\n",
    "    \n",
    "    for sentence in data:\n",
    "        for word in sentence:\n",
    "            if word not in word_count:\n",
    "                word_count[word] = 1\n",
    "            else:\n",
    "                word_count[word] += 1\n",
    "                \n",
    "    return word_count\n",
    "\n",
    "word_count = count_words(train+test+valid)\n",
    "word_count = sorted(word_count.items(), key=lambda x:x[1], reverse=True)\n",
    "\n",
    "uncommon_words = set(map(lambda x: x[0], filter(lambda x: x[1] <= 5, word_count)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total words:66081, uncommon words:44457\n"
     ]
    }
   ],
   "source": [
    "print(\"total words:{}, uncommon words:{}\".format(len(word_count), len(uncommon_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_uncommon_words(sentence, uncommon_words):\n",
    "    def sub_word(word):\n",
    "        if word in uncommon_words:\n",
    "            return '<UNK>'\n",
    "        else:\n",
    "            return word\n",
    "    return list(map(sub_word, sentence))\n",
    "\n",
    "train = list(map(lambda x:sub_uncommon_words(x, uncommon_words), train))\n",
    "test = list(map(lambda x:sub_uncommon_words(x, uncommon_words), test))\n",
    "valid = list(map(lambda x:sub_uncommon_words(x, uncommon_words), valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding:\n",
    "    def __init__(self, sentences, word_vec_size):\n",
    "        self.sentences = sentences\n",
    "        self.word_vec_size = word_vec_size\n",
    "        \n",
    "        self.model = None\n",
    "        self.embedding_matrix = None\n",
    "        \n",
    "        self._word2idx = {}\n",
    "        \n",
    "    def word2idx(self, word):\n",
    "        if self.model is None:\n",
    "            raise NameError('No model, use mk_embedding first.')\n",
    "        return self._word2idx[word]\n",
    "    \n",
    "    def idx2word(self, i):\n",
    "        if self.model is None:\n",
    "            raise NameError('No model, use mk_embedding first.')\n",
    "        return self.model.wv.index2word[i]\n",
    "    \n",
    "    def mk_embedding(self, load_model_path=None, save_model_path=None):\n",
    "        if load_model_path is not None:\n",
    "            model = Word2Vec.load(load_model_path)\n",
    "        else:\n",
    "            print('Word2Vec training ...')\n",
    "            model = Word2Vec(self.sentences, size=self.word_vec_size, window=5, workers=12, iter=10, sg=1)\n",
    "            if save_model_path is not None:\n",
    "                model.save(save_model_path)\n",
    "            else:\n",
    "                model.save('embedding/{}_word2vec.model'.format(self.word_vec_size))\n",
    "        \n",
    "        self.model = model\n",
    "        self.embedding_matrix = model.wv.vectors\n",
    "        for i, word in enumerate(model.wv.index2word):\n",
    "            self._word2idx[word] = i\n",
    "            \n",
    "        print('Embedding OK.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec training ...\n",
      "Embedding OK.\n"
     ]
    }
   ],
   "source": [
    "embedding = Embedding(train+test+valid, 150)\n",
    "embedding.mk_embedding('embedding/150_word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2idx(sentence):\n",
    "    return [embedding.word2idx(word) for word in sentence]\n",
    "\n",
    "train = list(map(word2idx, train))\n",
    "test = list(map(word2idx, test))\n",
    "valid = list(map(word2idx, valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[58, 8, 246, 10, 13, 9, 60, 292, 1054, 3, 1574, 207, 18, 2, 4984, 3, 51, 4069, 8, 70, 51, 236, 8, 14, 300, 11, 10, 13, 67, 817, 51, 4, 1, 566, 203, 4, 1, 87, 13, 15593, 342, 50, 1767, 61, 315, 509, 167, 160, 189, 3, 2, 1072, 1634, 793, 20, 5, 60, 378, 26, 114, 4, 10, 6, 5, 24, 276, 9, 4897, 4571, 12, 607, 70, 8, 266, 51, 311, 87, 8, 282, 26, 25, 91, 38, 270, 207, 1, 322, 6388, 92, 24, 184, 5, 165, 37, 25, 115, 1, 87, 13, 3, 37, 168, 7, 3241, 19, 1, 203, 527, 58, 1, 87, 81, 316, 136, 9, 19, 2, 647, 45, 21, 42, 612, 4897, 4571, 12, 607, 39, 1, 1314, 452, 32, 136, 623, 15, 43, 947, 3, 70, 1, 236, 8, 70, 1, 173, 154, 17, 2, 76, 2215, 4, 1, 87, 13, 3, 1, 509, 167, 46, 91, 1681, 35, 2, 26, 38, 779, 28, 18, 1, 418, 4, 2, 191, 57, 33, 1, 509, 4, 1031, 1, 151, 1295, 8887, 11, 76, 20, 1, 342, 9, 453, 6, 2, 458, 1492, 1, 727, 6, 101, 199, 755, 17, 7, 62, 33, 307, 289, 4, 15, 3729, 90, 1, 723, 843, 61, 80, 205, 1, 249, 47, 20, 3873, 5466, 7, 12, 26, 55, 50, 15, 3729, 289, 8, 5892, 229, 2, 723, 47, 298, 8, 282, 25, 20075, 335, 43, 1442, 5, 1, 304, 37, 756, 23, 115]\n"
     ]
    }
   ],
   "source": [
    "print(train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifer(nn.Module):\n",
    "    def __init__(self, embedding_matrix, hidden_size, seq_len, num_layers=1, fix_embedding=False):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(*embedding_matrix.shape)\n",
    "        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix))\n",
    "        self.embedding.weight.requires_grad = True if fix_embedding is True else False\n",
    "        \n",
    "        self.rnn = nn.GRU(embedding_matrix.shape[1], hidden_size, num_layers,\n",
    "                          batch_first=True, bidirectional=True)\n",
    "        \n",
    "        self.query = nn.Parameter(torch.rand(1,1,hidden_size*2))\n",
    "        self.query.requires_grad = True\n",
    "        \n",
    "        self.fc = nn.Sequential(nn.Dropout(0.2),\n",
    "                               nn.Linear(hidden_size*2, hidden_size//2),\n",
    "                               nn.ReLU(),\n",
    "                               \n",
    "                               nn.Dropout(0.2),\n",
    "                               nn.Linear(hidden_size//2, hidden_size//8),\n",
    "                               nn.ReLU(),\n",
    "                               \n",
    "                               nn.Linear(hidden_size//8, 1),\n",
    "                               nn.Sigmoid())\n",
    "        \n",
    "    def forward(self, input):\n",
    "        # input.shape is (batch size, sequence len, vocab size)\n",
    "        \n",
    "        embedding_seq = self.embedding(input)\n",
    "        output, hidden = self.rnn(embedding_seq)\n",
    "        # outputs shape is (batch_size, sequence_len, hid_size * directions)\n",
    "        # hidden shape is (num_layers * directions, batch_size, hid_size)\n",
    "        \n",
    "        similarity = torch.exp(sum(output @ self.query, 2))\n",
    "        # similarity.shape is (batch_size, sequence_len)\n",
    "        \n",
    "        att = similarity / torch.sum(similarity, 1).\n",
    "        \n",
    "        \n",
    "        prediction = self.fc(torch.sum(output*torch.unsqueeze(att, 2)))\n",
    "\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[[1,2,3],[3,4,5],[4,5,6]],[[2,3,4],[3,4,5],[5,6,7]]])\n",
    "b = torch.tensor([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[2,3,4],[5,3,2]],dtype=torch.float)\n",
    "b = torch.tensor([2,3],dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 3])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.x[i], self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.array(train)\n",
    "train_y = np.array(train_data['label'])\n",
    "\n",
    "val_x = np.array(valid)\n",
    "val_y = np.array(valid_data['label'])\n",
    "\n",
    "test_x = np.array(test)\n",
    "test_y = np.array(test_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = DataLoader(ReviewDataset(train_x, train_y), batch_size=128)\n",
    "val_set = DataLoader(ReviewDataset(val_x, val_y), batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 20\n",
    "hidden_size = 64\n",
    "seq_len = 250\n",
    "num_words = len(embedding.model.wv.index2word)\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total parameters:3331223\n"
     ]
    }
   ],
   "source": [
    "model = Classifer(embedding.embedding_matrix, hidden_size, seq_len, fix_embedding=True)\n",
    "model.to(device)\n",
    "print('total parameters:{}'.format(sum(p.numel() for p in model.parameters())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "calc_loss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_acc(pred, y):\n",
    "    pred = np.where(pred.detach().cpu().numpy() >= 0.5, 1, 0)\n",
    "    correct = np.sum(pred == y.detach().cpu().numpy())\n",
    "    return correct / y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (250) must match the size of tensor b (128) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-61ea527fbe74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-8f5ebfebc5f0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0matt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimilarity\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0;31m# outputs shape is (batch_size, sequence_len, hid_size * directions)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# hidden shape is (num_layers * directions, batch_size, hid_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (250) must match the size of tensor b (128) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epoch):\n",
    "    start_time = time.time()\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    val_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    \n",
    "    model.train()\n",
    "    for data in train_set:\n",
    "        x = data[0].to(dtype=torch.long, device=device)\n",
    "        y = data[1].to(dtype=torch.float, device=device)\n",
    "        \n",
    "        pred = model(x).squeeze()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        batch_loss = calc_loss(pred, y)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += batch_loss / len(train_set)\n",
    "        train_acc += calc_acc(pred, y) / len(train_set)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in val_set:\n",
    "            x = data[0].to(dtype=torch.long, device=device)\n",
    "            y = data[1].to(dtype=torch.float, device=device)\n",
    "            \n",
    "            pred = model(x).squeeze()\n",
    "            \n",
    "            batch_loss = calc_loss(pred, y)\n",
    "            \n",
    "            val_loss += batch_loss / len(val_set)\n",
    "            val_acc += calc_acc(pred, y) / len(val_set)\n",
    "            \n",
    "    print('epoch:[{:02d}/{:02d}] time:{:2.2f}(sec) train_loss:{:2.5f} train_acc:{:2.5f} | val_loss:{:2.5f} val_acc:{:2.5f}'.format(epoch+1, num_epoch, time.time() - start_time, train_loss, train_acc, val_loss, val_acc)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hidden_size=32 fix_embedding=False | val_loss:0.24784 val_acc:0.89609\n",
    "#hidden_size=64 fix_embedding=True | val_loss:0.23570 val_acc:0.90605"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
